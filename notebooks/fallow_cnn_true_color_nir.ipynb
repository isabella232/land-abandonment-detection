{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio as rs\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from matplotlib import pyplot as plt\n",
    "from rasterio.plot import reshape_as_image\n",
    "from rasterio.enums import Resampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.utils import class_weight\n",
    "from tqdm import tqdm\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "palette = sns.color_palette(\"coolwarm\", 5)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../data/training.pkl'):  \n",
    "    df = pd.read_csv('../data/training.csv', dtype={'id':str})\n",
    "    \n",
    "    initial_size = len(df)\n",
    "    print('Initial size %s:' % initial_size)\n",
    "\n",
    "    df = df[df['area'] > 0.15]\n",
    "    df = df[df['w'] >= 45]\n",
    "    df = df[df['h'] >= 45]\n",
    "\n",
    "    filtered_size = len(df)\n",
    "    print('After filtering size %s (%s):' % (filtered_size, filtered_size / initial_size))\n",
    "\n",
    "    data_path = '../data/fallow_land_sentinel'\n",
    "    out_shape=(4, 50, 50)\n",
    "    resampling=Resampling.nearest \n",
    "\n",
    "    def calculate_band(row):\n",
    "        raster = rs.open('%s/%s/%s/%s' % (data_path, row['researcher'], row['id'], row['file'])).read(\n",
    "            out_shape=out_shape, resampling=resampling\n",
    "        )\n",
    "        image = reshape_as_image(raster)\n",
    "        return image\n",
    "\n",
    "    df['image'] = df.progress_apply(calculate_band, axis=1)\n",
    "    df['global_id'] = df['researcher'] + df['id']\n",
    "    \n",
    "    df.to_pickle('../data/training.pkl')\n",
    "else:\n",
    "    df = pd.read_pickle('../data/training.pkl')\n",
    "         \n",
    "def calculate_correctness(row):\n",
    "    image = row['image']\n",
    "    return np.count_nonzero(image) / image.size\n",
    "    \n",
    "df['correctness'] = df.progress_apply(calculate_correctness, axis=1)\n",
    "df = df[df['correctness'] >= 0.9]        \n",
    "        \n",
    "print('Number of processed tiles: %s' % len(df))                      \n",
    "sns.countplot(x='grade', data=df, palette=palette)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_ids = df['global_id'].unique()\n",
    "train_ids, test_ids = train_test_split(global_ids, test_size=0.1, random_state=0)\n",
    "train_ids, val_ids = train_test_split(train_ids, test_size=0.1, random_state=0)\n",
    "\n",
    "train_df = df[df['global_id'].isin(train_ids)]\n",
    "test_df = df[df['global_id'].isin(test_ids)]\n",
    "val_df = df[df['global_id'].isin(val_ids)]\n",
    "\n",
    "del df\n",
    "\n",
    "pd.DataFrame({\n",
    "    'type': ['train', 'test', 'val'], \n",
    "    'count': [len(train_df), len(test_df), len(val_df)]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(image_edge_size=50, kernel_size=(3,3), pool_size=(2,2), filters=16):\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters, kernel_size, input_shape = (image_edge_size, image_edge_size, 4)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Conv2D(filters, kernel_size, use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPool2D(pool_size=pool_size)) \n",
    "    model.add(Dropout(rate=0.5))\n",
    "\n",
    "    model.add(Conv2D(filters*2, kernel_size, use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Conv2D(filters*2, kernel_size, use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPool2D(pool_size=pool_size))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "\n",
    "    model.add(Conv2D(filters*4, kernel_size, use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Conv2D(filters*4, kernel_size, use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))    \n",
    "    model.add(MaxPool2D(pool_size=pool_size))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(filters*8, use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train_df.image.tolist())\n",
    "y_train = np.array(train_df.label.tolist())\n",
    "\n",
    "X_test = np.array(test_df.image.tolist())\n",
    "y_test = np.array(test_df.label.tolist())\n",
    "\n",
    "X_val = np.array(val_df.image.tolist())\n",
    "y_val = np.array(val_df.label.tolist())\n",
    "\n",
    "del train_df\n",
    "del test_df\n",
    "del val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=0, restore_best_weights=True)\n",
    "reducelr = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=0, factor=0.1)\n",
    "tqmn_callback = TQDMNotebookCallback()\n",
    "\n",
    "history = model.fit(x=X_train, \n",
    "                    y=y_train, \n",
    "                    batch_size=32, \n",
    "                    epochs=24, \n",
    "                    verbose=0,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    class_weight=class_weights,\n",
    "                    callbacks=[reducelr, early_stopping, tqmn_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x=X_test, verbose=0)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "auc_r = auc(false_positive_rate, true_positive_rate)\n",
    "print('test auc: %f' % auc_r)\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('test loss:', score[0])\n",
    "print('test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(false_positive_rate, true_positive_rate, label='area = {:.5f}'.format(auc_r))\n",
    "plt.xlabel('false positive rate')\n",
    "plt.ylabel('true positive rate')\n",
    "plt.title('roc curve')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cls = model.predict_classes(x=X_test, verbose=0)\n",
    "cm = confusion_matrix(y_test, y_pred_cls)\n",
    "\n",
    "pd.DataFrame(cm, \n",
    "             index=['not a fallow', 'fallow'], \n",
    "             columns= ['predicted not a fallow', 'predicted fallow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/fallow_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}